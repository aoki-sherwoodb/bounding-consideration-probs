import pandas as pd
import numpy as np
from torch import tensor

from typing import Tuple
import os

PARENT_DIR = os.path.join(os.path.dirname(__file__), '')

def get_state_dicts(state_abrv_path: str = 'data/state_abrv.csv') -> Tuple[dict, dict, dict]:
    '''
    Creates mappings between state names, state postal abbreviations, and state IDs. 
    IDs are mapped by enumerating states from 0 in alphabetical order.

    @param state_abrv_path: path to state name and abbreviation data. Defaults to 'data/state_abrv.csv'.

    @return: three dictionaries {state name: ID}, {ID: state name}, {ID: state abbreviation}
    '''

    df = pd.read_csv(PARENT_DIR + state_abrv_path)

    # remove the District of Columbia because it is not a state
    df = df[df['Code']!= 'DC']

    states = df['State'] # alphabetically sorted in csv
    abrvs = df['Code']

    state_id = {state:id for state,id in zip(states, range(50))}
    id_state = {id:state for state,id in zip(states, range(50))}
    id_abrv = {id:abrv for abrv,id in zip(abrvs, range(50))}

    return state_id, id_state, id_abrv

def read_data(csv_path: str) -> pd.DataFrame:
    try:
        return pd.read_csv(PARENT_DIR + csv_path, index_col=0, encoding='latin-1')
    except FileNotFoundError:
        print(f"File not found at path {csv_path}. Please make sure that the state narcissism data csv "
               "is located at the input path relative to the root of this repository.")
        exit()

def get_top_3(data_path: str ='data/State Narcissism Scrubbed Data.csv') -> Tuple[tensor, tensor, tensor]:
    '''
    Reads in Top-3 data from csv. States are encoded as their IDs, generated by enumeration from 0 in alphabetical order.

    @return: three torch tensors: length 50 binary choice set vectors, chooser home state IDs, choice IDs.
    '''

    df = read_data(data_path)

    states = df['homeState'].unique()
    num_states = len(states)
    states.sort()
    state_id = {state:id for state,id in zip(states, range(num_states))}

    home_states = []
    choice_sets = []
    choices = []

    for row in df.itertuples():

        choosen_states = (state_id[getattr(row, 'contributedMostState')], 
                          state_id[getattr(row, 'contributed2ndMostState')], 
                          state_id[getattr(row, 'contributed3rdMostState')])

        # no invalid rankings
        if len(set(choosen_states))!= 3:
            continue

        home_state = state_id[getattr(row, 'homeState')]
        home_states.extend((home_state for _ in range(3)))

        choice_set_one = [1 for _ in range(num_states)]

        choice_set_two = choice_set_one.copy() 
        choice_set_two[choosen_states[0]] = 0

        choice_set_three = choice_set_two.copy()
        choice_set_three[choosen_states[1]] = 0

        choice_sets.extend((choice_set_one, choice_set_two, choice_set_three))

        choices.extend(choosen_states)

    return tensor(choice_sets), tensor(home_states), tensor(choices)

def get_random_10(data_path: str ='data/State Narcissism Scrubbed Data.csv') -> Tuple[tensor, tensor, tensor]:
    '''
    Reads in Random-10 data from csv. States are encoded as their IDs, generated by enumeration from 0 in alphabetical order.

    @return: three torch tensors: length 50 binary choice set vectors, chooser home state IDs, choice IDs.
    '''
    
    df = read_data(data_path)

    # 10 state rankings are located at columns 40 to 89
    df_r10 = df.iloc[:,40:90]
    df_r10['homeState'] = df['homeState']

    state_id, _, _ = get_state_dicts()
    states = list(state_id.keys())

    # rename df columns
    states.append('homeState')
    df_r10.columns = states

    home_states = []
    choice_sets = []
    choices = []


    def choices_and_choice_sets_from_row(r10_row: pd.Series) -> Tuple[list[str], np.array]:
        '''
        Helper to extract choices and choice sets from each row of data.
        For each sequential choice, the chosen item is removed from subsequent choice sets, except in the case of ties.
        Ties are broken alphabetically to construct the choice order, and tied items remain in the choice sets for all 
        tied choices.
        '''

        row = r10_row[r10_row.index != 'homeState']
        row = row[~row.isnull()]
        sorted_row = row.sort_values(ascending=False)
        choices = list(sorted_row.index)
        choices = [state_id[state_name] for state_name in choices]  # convert from name to ID

        choice_sets = np.zeros((len(choices), 50))  # one row per choice made, one column per item
        choice_sets[:, choices] = 1

        for i in range(len(choices)):
            state_score = sorted_row.iloc[i]
            n_already_chosen = len(sorted_row[sorted_row > state_score])  # strictly greater than so that tied items remain in choice set
            choice_sets[i, choices[:n_already_chosen]] = 0  # remove already-chosen items from choice set

        return choices, choice_sets
    

    for _, row in df_r10.iterrows():
        
        row_home_state = [state_id[row['homeState']]] * 10
        row_choices, row_choice_sets = choices_and_choice_sets_from_row(row)

        home_states.extend(row_home_state)
        choice_sets.extend(row_choice_sets)
        choices.extend(row_choices)

    return tensor(np.array(choice_sets)), tensor(home_states), tensor(choices)


def pairwise_matrix(choice_sets: tensor, choices: tensor) -> np.ndarray:
    '''
    Generates a matrix of pairwise win rates for all pairs of items given matching choice sets and choices.
    A pairwise win of item A over item B occurs when A is chosen from a choice set also containing B.

    @param choice_sets: an NxM tensor, where N is the number of choices and M is the size of the item universe.
    @param choices: a 1xN tensor of choices.
    @return: 50x50 array of state pairwise win rates.
    '''
    
    if len(choice_sets) != choices:
        print(f"Incompatible sizes for input choice sets {len(choice_sets)} and choices {len(choices)}.")
        exit()

    matrix = np.zeros((50, 50), dtype = 'float64')
    for i in range(len(choices)):
        choice = choices[i]
        for alternative in range(len(choice_sets[i])):
            matrix[choice, alternative] += choice_sets[i, alternative] 

    # normalize
    norm_matrix = np.copy(matrix)
    for i in range(len(matrix)):
        for j in range(len(matrix[i])):
            sum = matrix[i, j] + matrix[j, i]
            if sum == 0:
                norm_matrix[i, j] = 0
            else:
                norm_matrix[i, j] /= sum
                
    return norm_matrix

def topo_sort(dag: dict) -> list:
    """Perform a topological of a directed acyclic graph.

    @param dag: Input directed acyclic graph in adjacency list format as a dictionary of {node: [out-neighbors]}
    
    @return: list of graph nodes sorted in topological order.
    """
    in_degrees = {i: 0 for i in range(50)}
    for i in range(50):
        for j in range(50):
            if j in dag[i]:
                in_degrees[j] += 1
    sorted_nodes = sorted(in_degrees, key=lambda x:in_degrees[x])
    topo_G = []
    for node in sorted_nodes:
        if in_degrees[node] == 0:
            topo_G.append(node)
            for neighbor in dag[node]:
                in_degrees[neighbor] -= 1
    return topo_G


def get_topk_probs(choices_list: list, k: int = 3) -> list:
    '''
    Computes the empirical probabilities of items being ranked in the top j for each j from 1 to k. 

    @param k: the maximum length of rankings for which to compute empirical ranking probabilities.
    @param choices_list: list of item choices derived from a Top-k ranking setting. 

    @return: a k-element list of empirical Top-j ranking probabilities for each j from 1 to k.
    '''

    topk_probs = []

    for j in range(1, k + 1):
        topj_probs = [0] * 50

        for i in range(0, len(choices_list), 3):
            if i % 3 < j:
                topj_probs[choices_list[i]] += 1

        topk_probs.append(np.divide(topj_probs, len(choices_list) / 3))
    return topk_probs


def get_topk_swaps(choices_list: list, utilities: tensor, k: int = 3) -> dict:
    '''
    Calculates swaps in items based on inversions in relative Plackett-Luce utilities and empirical top-j ranking probabilities.
    We say there is a swap <i, j> if i has higher utility than j but has a lower empirical top-l ranking probability for some l from 1 to k.
    
     
    @param k: the maximum length of rankings for which to compute empirical ranking probabilities.
    @param choices_list: list of item choices derived from a Top-k ranking setting. 

    @return: a dictionary of swaps as described above.
    '''
    topk_swaps = {i: [] for i in range(50)}

    topk_probs = get_topk_probs(choices_list, k)

    for l in range(1, k + 1):
        topl_probs = topk_probs[l - 1]

        for i in range(50):
            for j in range(50):
                if i != j and utilities[i].item() > utilities[j].item() and topl_probs[i] < topl_probs[j] and j not in topk_swaps[i]:
                    topk_swaps[i].append(j)

    return topk_swaps






